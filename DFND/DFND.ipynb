{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.datasets import CIFAR10, CIFAR100, ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 网络定义"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 教师网络RestNet18, 34, 50, 101, 152"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out =F.relu(out)\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expasion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, out_feature=False):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        feature = out.view(out.size(0), -1)\n",
    "        out = self.linear(feature)\n",
    "        if out_feature == False:\n",
    "            return out\n",
    "        else:\n",
    "            return out, feature\n",
    "def ResNet18(num_classes=10):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n",
    " \n",
    "def ResNet34(num_classes=10):\n",
    "    return ResNet(BasicBlock, [3,4,6,3], num_classes)\n",
    " \n",
    "def ResNet50(num_classes=10):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], num_classes)\n",
    " \n",
    "def ResNet101(num_classes=10):\n",
    "    return ResNet(Bottleneck, [3,4,23,3], num_classes)\n",
    " \n",
    "def ResNet152(num_classes=10):\n",
    "    return ResNet(Bottleneck, [3,8,36,3], num_classes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 教师网络 LeNet5"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class LeNet5(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: [batch, 1, 32, 32]\n",
    "    Output:[batch, 10]\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5, 5))    #[28, 28]\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)  #[14, 14]\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(5, 5))       #[10, 10]\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)  #[5, 5]\n",
    "        self.conv3 = nn.Conv2d(16, 120, kernel_size=(5, 5)) #[1, 1]\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, img, out_feature=False):\n",
    "        output = self.conv1(img)\n",
    "        output = self.relu1(output)\n",
    "        output = self.maxpool1(output)  \n",
    "        \n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.maxpool2(output)\n",
    "        \n",
    "        output = self.conv3(output)\n",
    "        output = self.relu3(output)\n",
    "        \n",
    "        feature = output.view(-1, 120)\n",
    "        output = self.fc1(feature)\n",
    "        output = self.relu4(output)\n",
    "        output = self.fc2(output)\n",
    "        if out_feature == False:\n",
    "            return output\n",
    "        else:\n",
    "            return output,feature"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 教师网络训练"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class TeacherTrainer():\n",
    "    def __init__(self, epochs, path_dataset, path_ckpt):\n",
    "        self.net = LeNet5().cuda()\n",
    "        self.dataset_train = MNIST(path_dataset,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.Resize((32, 32)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                   ]))\n",
    "        self.dataset_test = MNIST(path_dataset,\n",
    "                                  train=False,\n",
    "                                  transforms=transforms.Compose([\n",
    "                                       transforms.Resize((32, 32)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                   ]))\n",
    "        self.dataset_train_loader = DataLoader(self.dataset_train, batch_size=256, shuffle=True, num_workers=8)\n",
    "        self.dataset_test_loader = DataLoader(self.dataset_test, batch_size=1024, num_workers=8)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().cdua()\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.001)\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 学生网络训练"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class StudentTrainer():\n",
    "    def __init__(self, epochs, name_dataset, path_dataset, path_imagenet, num_select):\n",
    "        self.epochs = epochs\n",
    "        # 测试数据集准备和教师网络\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        if name_dataset == 'cifar10':\n",
    "            self.data_test = CIFAR10(path_dataset,\n",
    "                                     train=False,\n",
    "                                     transform=transform_test)\n",
    "            self.teacher_acc = torch.Tensor([0.9523])\n",
    "            self.class_num = 10\n",
    "            self.teacher = ResNet34().cuda()\n",
    "        if name_dataset == 'cifar100':\n",
    "            self.data_test = CIFAR100(path_dataset,\n",
    "                                     train=False,\n",
    "                                     transform=transform_test)\n",
    "            self.teacher_acc = torch.Tensor([0.7774])\n",
    "            self.class_num = 100\n",
    "            self.teacher = ResNet34(num_classes=100).cuda()\n",
    "\n",
    "        self.data_test_loader = DataLoader(self.data_test, batch_size=1000, num_workers=8)\n",
    "        # 用于筛选正样本的原始训练数据集\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.data_train = ImageFolder(path_imagenet, transforms.Compose([\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "        self.data_train_loader_noshuffle = DataLoader(self.data_train, batch_szie=256, shuffle=False, num_workers=8)\n",
    "        #  从原始数据集中筛选\n",
    "        self.num_select = num_select\n",
    "        self.positive_index = self._select_dataset()\n",
    "        self.dataset_to_selected = ImageFolder(path_imagenet, transforms.Compose([\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "        self.dataset_selected = torch.utils.data.Subset(self.dataset_to_selected, self.positive_index)\n",
    "        self.dataset_selected_loader = torch.utils.data.DataLoader(self.dataset_selected, batch_size=256, shuffle=True, num_workers=8)\n",
    "        # 网络\n",
    "        self.noise_adaption = torch.nn.Parameter(torch.zeros(self.class_num, self.class_num-1))\n",
    "        self.student = ResNet18(self.class_num).cuda()\n",
    "        self.nll = nn.NLLLoss().cuda()      ## cross-entropy = softmax + log + nll(把log结果中对应labels的值取负，再求平均)\n",
    "        self.criterion = nn.CrossEntropyLoss().cuda()\n",
    "        self.optimizer = torch.optim.SGD(list(self.student.parameters()), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "        self.optimizer_noise = torch.optim.Adam([self.noise_adaption], lr=0.001)\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(1, self.epochs+1):\n",
    "            self.student.train()\n",
    "            for i, (images, labels) in enumerate(self.dataset_selected_loader):\n",
    "                images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                self.optimizer_noise.zero_grad()\n",
    "\n",
    "                output = self.student(images)\n",
    "                output_t = self.teacher(images).detach()\n",
    "                pseudo_labels = output_t.data.max(1)[1]\n",
    "                # 损失1：硬损失\n",
    "                loss = self._kdloss(output, output_t)\n",
    "                # 将学生预测结果[batch_size, class_num]乘以一个矩阵[class_num, class_num]\n",
    "                # 将相乘结果和伪标签求损失\n",
    "                output_s = F.softmax(output, dim=1)\n",
    "                output_s_adaption = torch.matmul(output_s, self._noise())\n",
    "                loss += self.nll(torch.log(output_s_adaption), pseudo_labels)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer_noise.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _kdloss(self, student_scores, teacher_scores, T=4):\n",
    "        p = F.log_softmax(student_scores/T, dim=1)\n",
    "        q = F.softmax(teacher_scores/T, dim=1)\n",
    "        l_kl = F.kl_div(p, q, reduce=False)\n",
    "        loss = torch.sum(l_kl) / teacher_scores.shape[0]\n",
    "        return loss * (T**2)\n",
    "\n",
    "    def _noise(self):\n",
    "        ## 把10x9的矩阵按行取softmax，再乘(1-teacher_acc)，再在对角线添加teacher_acc，得到一个10x10的矩阵\n",
    "        noise_adaption_softmax = F.softmax(self.noise_adaption, dim=1) * (1 - self.teacher_acc)\n",
    "        noise_adaption_layer = torch.zero(self.class_num, self.class_num)\n",
    "        for i in range(self.class_num):\n",
    "            if i == 0:\n",
    "                noise_adaption_layer[i] = torch.cat([self.teacher_acc, noise_adaption_softmax[i][i:]])\n",
    "            if i == self.class_num-1:\n",
    "                noise_adaption_layer[i] = torch.cat([noise_adaption_softmax[i][:i], self.teacher_acc])\n",
    "            else:\n",
    "                noise_adaption_layer[i] = torch.cat([noise_adaption_softmax[i][:i], self.teacher_acc, noise_adaption_softmax[i][i:]])\n",
    "        return noise_adaption_layer.cuda()\n",
    "    \n",
    "    def _select_dataset(self):\n",
    "        loss_list, pseudo_labels_list = self._identify_outlier()\n",
    "        positive_index = loss_list.topk(self.num_select, largest=False)[1]\n",
    "        positive_index = positive_index.tolist()\n",
    "        return positive_index\n",
    "\n",
    "\n",
    "    def _identify_outlier(self):\n",
    "        value = []\n",
    "        pseudo_labels_list = []\n",
    "        index = 0\n",
    "        celoss = nn.CrossEntropyLoss(reduction='none').cuda()\n",
    "        self.teacher.eval()\n",
    "        for i, (inputs, labels) in enumerate(self.data_train_loader_noshuffle, start=1):\n",
    "            inputs = inputs.cuda()\n",
    "            outputs = self.teacher(inputs)\n",
    "            pseudo_labels = outputs.data.max(1)[1]\n",
    "            loss = celoss(outputs, pseudo_labels)\n",
    "            value.append(loss.detach().clone())\n",
    "            index += inputs.shape[0]\n",
    "            pseudo_labels_list.append(pseudo_labels)\n",
    "        # cat将[tensor([1]),tensor([2])]改为tensor([1, 2])\n",
    "        return torch.cat(value, dim=0), torch.cat(pseudo_labels_list, dim=0)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}