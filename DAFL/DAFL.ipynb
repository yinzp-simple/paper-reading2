{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1-总体思路\n",
    "GAN + 知识蒸馏\n",
    "\n",
    "网络总共有:\n",
    "1. generator\n",
    "2. teacher（已经训练好）\n",
    "3. student"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "# import import_ipynb\n",
    "# from model import Generator, LeNet5, LeNet5Half"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2-网络的定义"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 教师网络LeNet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class LeNet5(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: [batch, 1, 32, 32]\n",
    "    Output:[batch, 10]\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5, 5))    #[28, 28]\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)  #[14, 14]\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(5, 5))       #[10, 10]\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)  #[5, 5]\n",
    "        self.conv3 = nn.Conv2d(16, 120, kernel_size=(5, 5)) #[1, 1]\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, img, out_feature=False):\n",
    "        output = self.conv1(img)\n",
    "        output = self.relu1(output)\n",
    "        output = self.maxpool1(output)  \n",
    "        \n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.maxpool2(output)\n",
    "        \n",
    "        output = self.conv3(output)\n",
    "        output = self.relu3(output)\n",
    "        \n",
    "        feature = output.view(-1, 120)\n",
    "        output = self.fc1(feature)\n",
    "        output = self.relu4(output)\n",
    "        output = self.fc2(output)\n",
    "        if out_feature == False:\n",
    "            return output\n",
    "        else:\n",
    "            return output,feature"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 学生网络LeNet5Half"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class LeNet5Half(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet5Half, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=(5, 5))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(3, 8, kernel_size=(5, 5))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(8, 60, kernel_size=(5, 5))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(60, 42)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(42, 10)\n",
    "\n",
    "    def forward(self, img, out_feature=False):\n",
    "        output = self.conv1(img)\n",
    "        output = self.relu1(output)\n",
    "        output = self.maxpool1(output)\n",
    "\n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.maxpool2(output)\n",
    "\n",
    "        output = self.conv3(output)\n",
    "        output = self.relu3(output)\n",
    "        feature = output.view(-1, 60)\n",
    "\n",
    "        output = self.fc1(feature)\n",
    "        output = self.relu4(output)\n",
    "        output = self.fc2(output)\n",
    "\n",
    "        if out_feature == False:\n",
    "            return output\n",
    "        else:\n",
    "            return output, feature"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3生成器网络\n",
    "input:[batch_size, 100]\n",
    "\n",
    "output:[batch_size, 32, 32]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Input:[batch, 100]\n",
    "    Out:[batch, 1, 32, 32]\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_size = 32 // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(100, 128*self.init_size**2))\n",
    "\n",
    "        self.conv_blocks0 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "        )\n",
    "        self.conv_blocks1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.conv_blocks2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 1, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(1, affine=False) \n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks0(out)\n",
    "        img = nn.functional.interpolate(img,scale_factor=2)\n",
    "        img = self.conv_blocks1(img)\n",
    "        img = nn.functional.interpolate(img,scale_factor=2)\n",
    "        img = self.conv_blocks2(img)\n",
    "        return img"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3-教师网络的训练"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "数据集：MNIST\n",
    "\n",
    "损失函数：交叉熵\n",
    "\n",
    "梯度更新方式：Adam\n",
    "\n",
    "学习率：lr = 0.001"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 训练类定义"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 开始训练及保存参数"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3-训练类定义\n",
    "激活损失函数：loss_activation\n",
    "\n",
    "生成器损失函数：loss_noe_hot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1教师网络训练类"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class TeacherTrainer:\n",
    "    def __init__(self):\n",
    "        self.teacher = LeNet5().cuda()\n",
    "        self.criterion = nn.CrossEntropyLoss().cuda()\n",
    "        self.optimizer = torch.optim.Adam(self.teacher.parameters(), lr = 0.001)\n",
    "        self.data_train = MNIST('~/workspace/dataset/', transform=transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]), download=False)\n",
    "        self.data_test = MNIST('~/workspace/dataset/', train=False, transform=transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "        self.data_train_loader = DataLoader(self.data_train, batch_size=256, shuffle=True, num_workers=8)\n",
    "        self.data_test_loader = DataLoader(self.data_test, batch_size=1024, num_workers=8)\n",
    "\n",
    "    def train(self, epochs):\n",
    "        self.teacher.train()\n",
    "        for epoch in range(1, epochs+1):\n",
    "            loss_list, batch_list = [], []\n",
    "            for i, (images, labels) in enumerate(self.data_train_loader, start=1):\n",
    "                images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.teacher(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss_list.append(loss.data.item())\n",
    "                batch_list.append(i+1)\n",
    "                # if i %100== 0:\n",
    "                #     print('Train-Epoch %d, Batch:%d, Loss %f' % (epoch, i, loss.data.item()))\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        \n",
    "            print('Finish epoch: %d, sum loss:%f' % (epoch, sum(loss_list)))\n",
    "            if epoch % 1== 0:\n",
    "                self.test()\n",
    "    \n",
    "    def test(self):\n",
    "        self.teacher.eval()\n",
    "        total_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(self.data_test_loader, start=1):\n",
    "                images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    "                output = self.teacher(images)\n",
    "                pred = output.data.max(1)[1]\n",
    "                total_correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "            \n",
    "        acc = float(total_correct) / len(self.data_test)\n",
    "        print('Test Accuracy:%f' % (acc))\n",
    "\n",
    "    def save_model(self, path, epochs):\n",
    "        state = {'net': self.teacher.state_dict(), 'optimizer':self.optimizer.state_dict(), 'epoch':epochs}\n",
    "        filename = path + 'net_epoch_%d.pth'%(epochs)\n",
    "        torch.save(state, filename)\n",
    "        \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2学生和生成器网络训练类"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "class StudentTrainer:\n",
    "    def __init__(self, teacher_ckpt_path, student_ckpt_path, path_dataset, epochs, batch_size, latent_dim, lr_G, lr_S, oh, ie, a):\n",
    "        ## 训练参数\n",
    "        self.epochs = epochs\n",
    "        self.lr_G = lr_G\n",
    "        self.lr_S = lr_S\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.oh = oh\n",
    "        self.ie = ie\n",
    "        self.a = a\n",
    "        self.student_ckpt_path = student_ckpt_path\n",
    "        ## 测试数据集\n",
    "        self.data_test = MNIST(path_dataset, train=False, transform=transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "        self.data_test_loader = DataLoader(self.data_test, batch_size=64, num_workers=8)\n",
    "        ## 网络定义\n",
    "        self.teacher = LeNet5().cuda()\n",
    "        self.teacher.load_state_dict(torch.load(teacher_ckpt_path)['net'])\n",
    "        self.student = LeNet5Half().cuda()\n",
    "        self.generate = Generator().cuda()\n",
    "        ## 损失函数和参数更新方式\n",
    "        self.criterion = nn.CrossEntropyLoss().cuda()\n",
    "        self.optimizer_G = torch.optim.Adam(self.generate.parameters(), lr = self.lr_G)\n",
    "        self.optimizer_S = torch.optim.Adam(self.student.parameters(), lr = self.lr_S)\n",
    "        \n",
    "    def train(self):\n",
    "        for epoch in range(1, epochs+1):\n",
    "            self.generate.train()\n",
    "            self.student.train()\n",
    "            loss_epoch = 0\n",
    "            for i in range(1, 121):\n",
    "                z = Variable(torch.randn(self.batch_size, self.latent_dim)).cuda()\n",
    "                self.optimizer_G.zero_grad()\n",
    "                self.optimizer_S.zero_grad()\n",
    "                gen_img = self.generate(z)\n",
    "                output, features = self.teacher(gen_img, out_feature = True)\n",
    "                pseudo_labels = output.data.max(1)[1]\n",
    "                # 用于纠正Generator的损失\n",
    "                ## 损失1：激活损失\n",
    "                loss_active = -features.abs().mean()\n",
    "                ## 损失2：one-hot损失\n",
    "                loss_onehot = self.criterion(output, pseudo_labels)\n",
    "                ## 损失3：信息熵损失\n",
    "                softmax_o_T = F.softmax(output, dim = 1).mean(dim=0)\n",
    "                loss_information_entropy = (softmax_o_T * torch.log10(softmax_o_T)).sum()\n",
    "\n",
    "                # 用于纠正学生网络的损失：知识蒸馏损失\n",
    "                loss_kd = self.kdloss(self.student(gen_img.detach()), output.detach())\n",
    "\n",
    "                loss = loss_onehot * self.oh + loss_information_entropy * self.ie + loss_active * self.a + loss_kd\n",
    "                loss.backward()\n",
    "                self.optimizer_S.step()\n",
    "                self.optimizer_G.step()\n",
    "                loss_epoch += loss.data.item()\n",
    "            print('Epoch%d, loss%f' % (epoch, loss_epoch))\n",
    "            self.test(epoch)\n",
    "\n",
    "    def test(self, epoch):\n",
    "        total_corerect = 0\n",
    "        best_accr = 0\n",
    "        best_epoch = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(self.data_test_loader, start=1):\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "                self.student.eval()\n",
    "                output = self.student(images)\n",
    "                pred = output.data.max(1)[1]\n",
    "                total_corerect += pred.eq(labels.view_as(pred)).sum()\n",
    "        accr = float(total_corerect) / len(self.data_test)\n",
    "        print('Test Accuracy: %f' % (accr))\n",
    "        if accr > best_accr:\n",
    "            best_accr, best_epoch = accr, epoch\n",
    "            self.save_model(best_epoch, best_accr)\n",
    "\n",
    "    def kdloss(self, y, teacher_scores):\n",
    "        p = F.log_softmax(y, dim=1)\n",
    "        q = F.softmax(teacher_scores, dim=1)\n",
    "        l_kl = F.kl_div(p, q, size_average=False) / y.shape[0]\n",
    "        return l_kl\n",
    "    \n",
    "    def save_model(self, epochs, accr):\n",
    "        state = {'net': self.student.state_dict(), 'optimizer':self.optimizer_S.state_dict(), 'epoch':epochs}\n",
    "        filename = self.student_ckpt_path + 'student_accr%f_epoch_%d.pth' %(accr, epochs)\n",
    "        torch.save(state, filename)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 开始训练"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练教师网络"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "trainteacher = TeacherTrainer()\n",
    "epochs = 20\n",
    "trainteacher.train(epochs)\n",
    "path = os.getcwd() + '/cache/models/'\n",
    "trainteacher.save_model('cache/models/', epochs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/yinzp/.local/lib/python3.6/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "/home/yinzp/.local/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finish epoch: 1, sum loss:101.072858\n",
      "Test Accuracy:0.962800\n",
      "Finish epoch: 2, sum loss:24.796381\n",
      "Test Accuracy:0.978200\n",
      "Finish epoch: 3, sum loss:16.870111\n",
      "Test Accuracy:0.982900\n",
      "Finish epoch: 4, sum loss:13.435808\n",
      "Test Accuracy:0.981900\n",
      "Finish epoch: 5, sum loss:11.124334\n",
      "Test Accuracy:0.985200\n",
      "Finish epoch: 6, sum loss:9.164217\n",
      "Test Accuracy:0.985900\n",
      "Finish epoch: 7, sum loss:8.336562\n",
      "Test Accuracy:0.983500\n",
      "Finish epoch: 8, sum loss:7.125623\n",
      "Test Accuracy:0.988100\n",
      "Finish epoch: 9, sum loss:6.302748\n",
      "Test Accuracy:0.989300\n",
      "Finish epoch: 10, sum loss:5.492025\n",
      "Test Accuracy:0.989400\n",
      "Finish epoch: 11, sum loss:5.196884\n",
      "Test Accuracy:0.991200\n",
      "Finish epoch: 12, sum loss:4.570235\n",
      "Test Accuracy:0.988500\n",
      "Finish epoch: 13, sum loss:3.954003\n",
      "Test Accuracy:0.988200\n",
      "Finish epoch: 14, sum loss:3.541092\n",
      "Test Accuracy:0.989000\n",
      "Finish epoch: 15, sum loss:3.209433\n",
      "Test Accuracy:0.988700\n",
      "Finish epoch: 16, sum loss:2.979558\n",
      "Test Accuracy:0.991400\n",
      "Finish epoch: 17, sum loss:3.152918\n",
      "Test Accuracy:0.988500\n",
      "Finish epoch: 18, sum loss:2.538099\n",
      "Test Accuracy:0.991400\n",
      "Finish epoch: 19, sum loss:1.955358\n",
      "Test Accuracy:0.991800\n",
      "Finish epoch: 20, sum loss:2.234557\n",
      "Test Accuracy:0.990300\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练学生网络\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "current_path = os.getcwd()\n",
    "path_ckpt_t_teacher = current_path + '/cache/models/net_epoch_20.\n",
    "ckpt_path_student = current_path + '/cache/models'\n",
    "path_dataset = '/home/yinzp/workspace/dataset/'\n",
    "lr_G = 0.2\n",
    "lr_S = 2e-3\n",
    "epochs = 50\n",
    "batch_size = 512\n",
    "latent_dim = 100\n",
    "oh = 1\n",
    "ie = 5\n",
    "a = 0.1\n",
    "torch.cuda.empty_cache()\n",
    "trainstudent = StudentTrainer(path_ckpt_t_teacher, ckpt_path_student, path_dataset, epochs, batch_size, latent_dim, lr_G, lr_S, oh, ie, a)\n",
    "trainstudent.train()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch1, loss-414.989403\n",
      "Test Accuracy: 0.609200\n",
      "Epoch2, loss-481.897155\n",
      "Test Accuracy: 0.825900\n",
      "Epoch3, loss-508.609571\n",
      "Test Accuracy: 0.863800\n",
      "Epoch4, loss-520.428852\n",
      "Test Accuracy: 0.900500\n",
      "Epoch5, loss-522.409932\n",
      "Test Accuracy: 0.885700\n",
      "Epoch6, loss-525.143704\n",
      "Test Accuracy: 0.925700\n",
      "Epoch7, loss-443.878463\n",
      "Test Accuracy: 0.725800\n",
      "Epoch8, loss-386.356447\n",
      "Test Accuracy: 0.724700\n",
      "Epoch9, loss-386.357029\n",
      "Test Accuracy: 0.724700\n",
      "Epoch10, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch11, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch12, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch13, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch14, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch15, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch16, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch17, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch18, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch19, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch20, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch21, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch22, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch23, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch24, loss-386.357030\n",
      "Test Accuracy: 0.724700\n",
      "Epoch25, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch26, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch27, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch28, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch29, loss-386.357030\n",
      "Test Accuracy: 0.724700\n",
      "Epoch30, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch31, loss-386.357030\n",
      "Test Accuracy: 0.724700\n",
      "Epoch32, loss-386.357030\n",
      "Test Accuracy: 0.724700\n",
      "Epoch33, loss-386.357030\n",
      "Test Accuracy: 0.724700\n",
      "Epoch34, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch35, loss-386.357030\n",
      "Test Accuracy: 0.724700\n",
      "Epoch36, loss-386.357030\n",
      "Test Accuracy: 0.724700\n",
      "Epoch37, loss-386.357030\n",
      "Test Accuracy: 0.724700\n",
      "Epoch38, loss-386.357030\n",
      "Test Accuracy: 0.724700\n",
      "Epoch39, loss-386.357030\n",
      "Test Accuracy: 0.724700\n",
      "Epoch40, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch41, loss-386.357029\n",
      "Test Accuracy: 0.724700\n",
      "Epoch42, loss-386.357030\n",
      "Test Accuracy: 0.724700\n",
      "Epoch43, loss-386.357031\n",
      "Test Accuracy: 0.724700\n",
      "Epoch44, loss-386.357030\n",
      "Test Accuracy: 0.724700\n",
      "Epoch45, loss-386.357030\n",
      "Test Accuracy: 0.724700\n",
      "Epoch46, loss-386.357029\n",
      "Test Accuracy: 0.724700\n",
      "Epoch47, loss-386.357030\n",
      "Test Accuracy: 0.724600\n",
      "Epoch48, loss-386.357030\n",
      "Test Accuracy: 0.724600\n",
      "Epoch49, loss-386.357030\n",
      "Test Accuracy: 0.724600\n",
      "Epoch50, loss-386.357030\n",
      "Test Accuracy: 0.724600\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def save_list(list, path, filename):\n",
    "    file = open(path + filename, 'w')\n",
    "    for i in range(len(list)):\n",
    "        file.write(str(list[i]))\n",
    "        file.write('\\n')\n",
    "    file.close\n",
    "def save_model(epoch):\n",
    "    s_path = 'cache/models/student%d.pth'%(epoch)\n",
    "    g_path = 'cache/models/generate%d.pth'%(epoch)\n",
    "    state = {'net': student.state_dict(), 'optimizer':optimizer_S.state_dict(), 'epoch':epochs}\n",
    "    torch.save(state, s_path)\n",
    "    state = {'net': generator.state_dict(), 'optimizer':optimizer_G.state_dict(), 'epoch':epochs}\n",
    "    torch.save(state, g_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "loss_l, loss_kd_l, loss_ie_l, loss_oh_l, loss_a_l, accr_l = [], [], [], [], [], []\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(1, epochs+1):\n",
    "    loss_s, loss_oh_s, loss_a_s, loss_ie_s, loss_kd_s= 0, 0, 0, 0, 0\n",
    "    for i in range(1, 121):\n",
    "        student.train()\n",
    "        generator.train()\n",
    "        z = Variable(torch.randn(batch_size, latent_dim)).cuda()\n",
    "        optimizer_G.zero_grad()\n",
    "        optimizer_S.zero_grad()\n",
    "        gen_images = generator(z)\n",
    "        outputs_T, features_T = teacher(gen_images, out_feature=True)\n",
    "        pred = outputs_T.data.max(1)[1]\n",
    "        ## 损失1--激活损失\n",
    "        loss_activation = -features_T.abs().mean()\n",
    "        ## 损失2\n",
    "        loss_one_hot = criterion(outputs_T, pred)\n",
    "        ## 损失3\n",
    "        softmax_o_T = F.softmax(outputs_T, dim=1).mean(dim=0)\n",
    "        loss_information_entropy = (softmax_o_T * torch.log10(softmax_o_T)).sum()\n",
    "        ## 总损失\n",
    "        loss = loss_one_hot * oh + loss_information_entropy * ie + loss_activation * a\n",
    "\n",
    "        ## 用于优化学生网络的知识蒸馏损失\n",
    "        loss_kd = kdloss(student(gen_images.detach()), outputs_T.detach())\n",
    "        loss += loss_kd\n",
    "        loss.backward()\n",
    "        optimizer_G.step()\n",
    "        optimizer_S.step()\n",
    "        ## 累计损失\n",
    "        loss_s += loss.data.item()\n",
    "        loss_a_s += loss_activation.data.item()\n",
    "        loss_ie_s += loss_information_entropy.data.item()\n",
    "        loss_oh_s += loss_one_hot.data.item()\n",
    "        loss_kd_s += loss_kd.data.item()\n",
    "\n",
    "        \n",
    "    \n",
    "    ## 结束一个epoch\n",
    "    loss_l.append(loss_s)\n",
    "    loss_a_l.append(loss_a_s)\n",
    "    loss_ie_l.append(loss_ie_s)\n",
    "    loss_oh_l.append(loss_oh_s)\n",
    "    loss_kd_l.append(loss_kd_s)\n",
    "    print('Epoch%d, loss%f, loss_oh:%f, loss_ie:%f, loss_a:%f, loss_kd:%f' % (epoch, loss_s, loss_oh_s, loss_ie_s, loss_a_s, loss_kd_s))\n",
    "    total_corerect = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(data_test_loader, start=1):\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            student.eval()\n",
    "            output = student(images)\n",
    "            pred = output.data.max(1)[1]\n",
    "            total_corerect += pred.eq(labels.view_as(pred)).sum()\n",
    "    accr = float(total_corerect) / len(data_test)\n",
    "    accr_l.append(accr)\n",
    "    print('Test Accuracy: %f' % (accr))\n",
    "    if epoch%20 == 0:\n",
    "        save_model(epoch)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/yinzp/.local/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch1, loss-423.809659, loss_oh:39.549178, loss_ie:-116.175034, loss_a:-170.437260, loss_kd:134.560059\n",
      "Test Accuracy: 0.481800\n",
      "Epoch2, loss-498.079248, loss_oh:35.703057, loss_ie:-118.230725, loss_a:-178.568815, loss_kd:75.228198\n",
      "Test Accuracy: 0.701300\n",
      "Epoch3, loss-522.322384, loss_oh:34.482052, loss_ie:-118.655312, loss_a:-196.556510, loss_kd:56.127772\n",
      "Test Accuracy: 0.847800\n",
      "Epoch4, loss-534.332417, loss_oh:34.483799, loss_ie:-118.676752, loss_a:-181.096145, loss_kd:42.677158\n",
      "Test Accuracy: 0.911200\n",
      "Epoch5, loss-540.048560, loss_oh:32.938086, loss_ie:-118.605378, loss_a:-206.691228, loss_kd:40.709370\n",
      "Test Accuracy: 0.946800\n",
      "Epoch6, loss-526.139665, loss_oh:37.252659, loss_ie:-116.936448, loss_a:-179.553354, loss_kd:39.245259\n",
      "Test Accuracy: 0.932700\n",
      "Epoch7, loss-539.169344, loss_oh:36.853369, loss_ie:-118.631240, loss_a:-177.298605, loss_kd:34.863345\n",
      "Test Accuracy: 0.946800\n",
      "Epoch8, loss-537.478224, loss_oh:35.957967, loss_ie:-118.319979, loss_a:-186.753548, loss_kd:36.839061\n",
      "Test Accuracy: 0.956400\n",
      "Epoch9, loss-542.478651, loss_oh:33.909719, loss_ie:-118.700900, loss_a:-194.552180, loss_kd:36.571346\n",
      "Test Accuracy: 0.954200\n",
      "Epoch10, loss-549.549111, loss_oh:31.596008, loss_ie:-118.905164, loss_a:-203.339096, loss_kd:33.714605\n",
      "Test Accuracy: 0.961800\n",
      "Epoch11, loss-549.379790, loss_oh:31.385673, loss_ie:-118.760358, loss_a:-209.114311, loss_kd:33.947758\n",
      "Test Accuracy: 0.961100\n",
      "Epoch12, loss-541.403739, loss_oh:39.667501, loss_ie:-118.578314, loss_a:-199.819207, loss_kd:31.802242\n",
      "Test Accuracy: 0.950800\n",
      "Epoch13, loss-548.480601, loss_oh:32.307949, loss_ie:-118.271388, loss_a:-205.963046, loss_kd:31.164691\n",
      "Test Accuracy: 0.955100\n",
      "Epoch14, loss-551.077168, loss_oh:33.020079, loss_ie:-118.672586, loss_a:-202.317206, loss_kd:29.497405\n",
      "Test Accuracy: 0.955700\n",
      "Epoch15, loss-551.972667, loss_oh:31.198211, loss_ie:-118.451689, loss_a:-211.472993, loss_kd:30.234864\n",
      "Test Accuracy: 0.962600\n",
      "Epoch16, loss-548.388474, loss_oh:34.944976, loss_ie:-118.753930, loss_a:-181.554102, loss_kd:28.591607\n",
      "Test Accuracy: 0.955600\n",
      "Epoch17, loss-548.636404, loss_oh:36.511682, loss_ie:-118.726594, loss_a:-174.327418, loss_kd:25.917622\n",
      "Test Accuracy: 0.956700\n",
      "Epoch18, loss-548.245198, loss_oh:36.345351, loss_ie:-118.577806, loss_a:-175.088553, loss_kd:25.807332\n",
      "Test Accuracy: 0.948800\n",
      "Epoch19, loss-541.519526, loss_oh:38.090135, loss_ie:-117.775786, loss_a:-170.107426, loss_kd:26.280009\n",
      "Test Accuracy: 0.950300\n",
      "Epoch20, loss-550.495775, loss_oh:35.844929, loss_ie:-118.493716, loss_a:-172.798465, loss_kd:23.407721\n",
      "Test Accuracy: 0.962100\n",
      "Epoch21, loss-552.145059, loss_oh:34.263243, loss_ie:-118.404051, loss_a:-185.464922, loss_kd:24.158448\n",
      "Test Accuracy: 0.964200\n",
      "Epoch22, loss-550.394333, loss_oh:33.437072, loss_ie:-117.960262, loss_a:-198.080708, loss_kd:25.777973\n",
      "Test Accuracy: 0.964700\n",
      "Epoch23, loss-552.892349, loss_oh:34.021618, loss_ie:-118.602631, loss_a:-187.478111, loss_kd:24.846999\n",
      "Test Accuracy: 0.965300\n",
      "Epoch24, loss-553.041863, loss_oh:35.378534, loss_ie:-118.692258, loss_a:-178.467409, loss_kd:22.887627\n",
      "Test Accuracy: 0.968800\n",
      "Epoch25, loss-552.340662, loss_oh:35.239830, loss_ie:-118.379318, loss_a:-180.108598, loss_kd:22.326960\n",
      "Test Accuracy: 0.968400\n",
      "Epoch26, loss-551.724039, loss_oh:35.755926, loss_ie:-118.187278, loss_a:-180.616373, loss_kd:21.518064\n",
      "Test Accuracy: 0.969200\n",
      "Epoch27, loss-549.991765, loss_oh:35.683792, loss_ie:-117.713623, loss_a:-179.365604, loss_kd:20.829117\n",
      "Test Accuracy: 0.972600\n",
      "Epoch28, loss-538.263159, loss_oh:43.822600, loss_ie:-116.975354, loss_a:-183.940406, loss_kd:21.185040\n",
      "Test Accuracy: 0.971500\n",
      "Epoch29, loss-551.602590, loss_oh:36.643304, loss_ie:-118.426233, loss_a:-171.686920, loss_kd:21.053957\n",
      "Test Accuracy: 0.968100\n",
      "Epoch30, loss-549.947280, loss_oh:37.261594, loss_ie:-118.248943, loss_a:-174.781615, loss_kd:21.514005\n",
      "Test Accuracy: 0.970400\n",
      "Epoch31, loss-553.238513, loss_oh:35.158970, loss_ie:-118.414788, loss_a:-188.302895, loss_kd:22.506748\n",
      "Test Accuracy: 0.967400\n",
      "Epoch32, loss-554.290290, loss_oh:35.747778, loss_ie:-118.730104, loss_a:-177.526935, loss_kd:21.365141\n",
      "Test Accuracy: 0.973000\n",
      "Epoch33, loss-549.728977, loss_oh:36.688828, loss_ie:-117.950912, loss_a:-179.757464, loss_kd:21.312501\n",
      "Test Accuracy: 0.970300\n",
      "Epoch34, loss-552.857799, loss_oh:36.757372, loss_ie:-118.602377, loss_a:-177.116733, loss_kd:21.108387\n",
      "Test Accuracy: 0.971100\n",
      "Epoch35, loss-552.263906, loss_oh:36.640737, loss_ie:-118.374462, loss_a:-175.634865, loss_kd:20.531157\n",
      "Test Accuracy: 0.970600\n",
      "Epoch36, loss-551.798158, loss_oh:36.616431, loss_ie:-118.339889, loss_a:-178.045019, loss_kd:21.089358\n",
      "Test Accuracy: 0.968200\n",
      "Epoch37, loss-552.882128, loss_oh:35.081123, loss_ie:-118.283321, loss_a:-197.976185, loss_kd:23.250977\n",
      "Test Accuracy: 0.970100\n",
      "Epoch38, loss-428.919742, loss_oh:162.590847, loss_ie:-118.655650, loss_a:-84.801136, loss_kd:10.247780\n",
      "Test Accuracy: 0.852700\n",
      "Epoch39, loss-363.568456, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000070\n",
      "Test Accuracy: 0.852900\n",
      "Epoch40, loss-363.568524, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000004\n",
      "Test Accuracy: 0.852900\n",
      "Epoch41, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch42, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch43, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000004\n",
      "Test Accuracy: 0.852900\n",
      "Epoch44, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.852900\n",
      "Epoch45, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000006\n",
      "Test Accuracy: 0.852900\n",
      "Epoch46, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch47, loss-363.568524, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.852900\n",
      "Epoch48, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch49, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000004\n",
      "Test Accuracy: 0.852900\n",
      "Epoch50, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.852900\n",
      "Epoch51, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000004\n",
      "Test Accuracy: 0.852900\n",
      "Epoch52, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.852900\n",
      "Epoch53, loss-363.568524, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000004\n",
      "Test Accuracy: 0.852900\n",
      "Epoch54, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.852900\n",
      "Epoch55, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch56, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch57, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.852900\n",
      "Epoch58, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch59, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.852900\n",
      "Epoch60, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch61, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.852900\n",
      "Epoch62, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch63, loss-363.568524, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.852900\n",
      "Epoch64, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch65, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.852900\n",
      "Epoch66, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000004\n",
      "Test Accuracy: 0.852900\n",
      "Epoch67, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.852900\n",
      "Epoch68, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.852900\n",
      "Epoch69, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch70, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch71, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.852900\n",
      "Epoch72, loss-363.568526, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch73, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.852900\n",
      "Epoch74, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.852900\n",
      "Epoch75, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.852900\n",
      "Epoch76, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch77, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch78, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch79, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000000\n",
      "Test Accuracy: 0.852900\n",
      "Epoch80, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch81, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch82, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000000\n",
      "Test Accuracy: 0.852900\n",
      "Epoch83, loss-363.568526, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.852900\n",
      "Epoch84, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.852900\n",
      "Epoch85, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.852900\n",
      "Epoch86, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.852900\n",
      "Epoch87, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000000\n",
      "Test Accuracy: 0.852900\n",
      "Epoch88, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch89, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.852900\n",
      "Epoch90, loss-363.568526, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000000\n",
      "Test Accuracy: 0.852900\n",
      "Epoch91, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.852900\n",
      "Epoch92, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000000\n",
      "Test Accuracy: 0.853000\n",
      "Epoch93, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.853000\n",
      "Epoch94, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.853000\n",
      "Epoch95, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.852700\n",
      "Epoch96, loss-363.568216, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000310\n",
      "Test Accuracy: 0.852400\n",
      "Epoch97, loss-363.568243, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000284\n",
      "Test Accuracy: 0.853400\n",
      "Epoch98, loss-363.568099, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000428\n",
      "Test Accuracy: 0.853100\n",
      "Epoch99, loss-363.568333, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000193\n",
      "Test Accuracy: 0.851800\n",
      "Epoch100, loss-363.568358, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000169\n",
      "Test Accuracy: 0.853500\n",
      "Epoch101, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.853600\n",
      "Epoch102, loss-363.567967, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000558\n",
      "Test Accuracy: 0.854000\n",
      "Epoch103, loss-363.568148, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000377\n",
      "Test Accuracy: 0.855200\n",
      "Epoch104, loss-363.568526, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:-0.000000\n",
      "Test Accuracy: 0.855200\n",
      "Epoch105, loss-363.567957, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000569\n",
      "Test Accuracy: 0.855300\n",
      "Epoch106, loss-363.568245, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000281\n",
      "Test Accuracy: 0.856100\n",
      "Epoch107, loss-363.568263, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000262\n",
      "Test Accuracy: 0.854500\n",
      "Epoch108, loss-363.568230, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000296\n",
      "Test Accuracy: 0.857700\n",
      "Epoch109, loss-363.568086, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000441\n",
      "Test Accuracy: 0.858000\n",
      "Epoch110, loss-363.568516, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000010\n",
      "Test Accuracy: 0.858500\n",
      "Epoch111, loss-363.567651, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000876\n",
      "Test Accuracy: 0.858300\n",
      "Epoch112, loss-363.568416, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000111\n",
      "Test Accuracy: 0.859800\n",
      "Epoch113, loss-363.567876, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000650\n",
      "Test Accuracy: 0.859600\n",
      "Epoch114, loss-363.568155, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000372\n",
      "Test Accuracy: 0.859900\n",
      "Epoch115, loss-363.568497, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000030\n",
      "Test Accuracy: 0.860900\n",
      "Epoch116, loss-363.567688, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000838\n",
      "Test Accuracy: 0.859800\n",
      "Epoch117, loss-363.568249, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000276\n",
      "Test Accuracy: 0.860600\n",
      "Epoch118, loss-363.568499, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000026\n",
      "Test Accuracy: 0.861900\n",
      "Epoch119, loss-363.567694, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000832\n",
      "Test Accuracy: 0.863300\n",
      "Epoch120, loss-363.568432, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000095\n",
      "Test Accuracy: 0.866500\n",
      "Epoch121, loss-363.567923, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000603\n",
      "Test Accuracy: 0.860100\n",
      "Epoch122, loss-363.568521, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000006\n",
      "Test Accuracy: 0.860100\n",
      "Epoch123, loss-363.567564, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000962\n",
      "Test Accuracy: 0.867600\n",
      "Epoch124, loss-363.568502, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000024\n",
      "Test Accuracy: 0.867600\n",
      "Epoch125, loss-363.568175, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000351\n",
      "Test Accuracy: 0.864900\n",
      "Epoch126, loss-363.568312, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000214\n",
      "Test Accuracy: 0.860000\n",
      "Epoch127, loss-363.567901, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000625\n",
      "Test Accuracy: 0.864700\n",
      "Epoch128, loss-363.568479, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000047\n",
      "Test Accuracy: 0.864600\n",
      "Epoch129, loss-363.568136, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000389\n",
      "Test Accuracy: 0.860800\n",
      "Epoch130, loss-363.568413, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000113\n",
      "Test Accuracy: 0.856400\n",
      "Epoch131, loss-363.568131, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000396\n",
      "Test Accuracy: 0.862700\n",
      "Epoch132, loss-363.568115, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000412\n",
      "Test Accuracy: 0.861000\n",
      "Epoch133, loss-363.568401, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000126\n",
      "Test Accuracy: 0.857600\n",
      "Epoch134, loss-363.568352, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000173\n",
      "Test Accuracy: 0.855900\n",
      "Epoch135, loss-363.567979, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000548\n",
      "Test Accuracy: 0.855500\n",
      "Epoch136, loss-363.568307, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000218\n",
      "Test Accuracy: 0.853900\n",
      "Epoch137, loss-363.568186, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000340\n",
      "Test Accuracy: 0.853000\n",
      "Epoch138, loss-363.568497, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000029\n",
      "Test Accuracy: 0.853600\n",
      "Epoch139, loss-363.568015, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000511\n",
      "Test Accuracy: 0.844600\n",
      "Epoch140, loss-363.568464, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000062\n",
      "Test Accuracy: 0.847700\n",
      "Epoch141, loss-363.567912, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000614\n",
      "Test Accuracy: 0.836700\n",
      "Epoch142, loss-363.568489, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000039\n",
      "Test Accuracy: 0.837200\n",
      "Epoch143, loss-363.568241, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000285\n",
      "Test Accuracy: 0.841800\n",
      "Epoch144, loss-363.568478, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000048\n",
      "Test Accuracy: 0.840500\n",
      "Epoch145, loss-363.568102, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000423\n",
      "Test Accuracy: 0.829300\n",
      "Epoch146, loss-363.568315, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000212\n",
      "Test Accuracy: 0.836100\n",
      "Epoch147, loss-363.568311, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000215\n",
      "Test Accuracy: 0.830300\n",
      "Epoch148, loss-363.568477, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000049\n",
      "Test Accuracy: 0.830400\n",
      "Epoch149, loss-363.568099, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000427\n",
      "Test Accuracy: 0.834100\n",
      "Epoch150, loss-363.568502, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000023\n",
      "Test Accuracy: 0.831400\n",
      "Epoch151, loss-363.567884, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000643\n",
      "Test Accuracy: 0.829700\n",
      "Epoch152, loss-363.567590, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000936\n",
      "Test Accuracy: 0.808400\n",
      "Epoch153, loss-363.568526, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.808400\n",
      "Epoch154, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.808400\n",
      "Epoch155, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.808400\n",
      "Epoch156, loss-363.568207, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000319\n",
      "Test Accuracy: 0.819500\n",
      "Epoch157, loss-363.568524, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000003\n",
      "Test Accuracy: 0.819400\n",
      "Epoch158, loss-363.568441, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000085\n",
      "Test Accuracy: 0.817900\n",
      "Epoch159, loss-363.568368, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000157\n",
      "Test Accuracy: 0.815400\n",
      "Epoch160, loss-363.568392, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000135\n",
      "Test Accuracy: 0.813600\n",
      "Epoch161, loss-363.568426, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000102\n",
      "Test Accuracy: 0.815500\n",
      "Epoch162, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.815700\n",
      "Epoch163, loss-363.568206, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000321\n",
      "Test Accuracy: 0.811200\n",
      "Epoch164, loss-363.568358, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000168\n",
      "Test Accuracy: 0.796600\n",
      "Epoch165, loss-363.568520, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000007\n",
      "Test Accuracy: 0.795500\n",
      "Epoch166, loss-363.568332, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000193\n",
      "Test Accuracy: 0.797500\n",
      "Epoch167, loss-363.568380, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000145\n",
      "Test Accuracy: 0.795400\n",
      "Epoch168, loss-363.568397, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000129\n",
      "Test Accuracy: 0.794300\n",
      "Epoch169, loss-363.568475, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000050\n",
      "Test Accuracy: 0.791600\n",
      "Epoch170, loss-363.566383, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.002142\n",
      "Test Accuracy: 0.698200\n",
      "Epoch171, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.698200\n",
      "Epoch172, loss-363.568365, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000162\n",
      "Test Accuracy: 0.706100\n",
      "Epoch173, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.706100\n",
      "Epoch174, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.706100\n",
      "Epoch175, loss-363.568353, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000173\n",
      "Test Accuracy: 0.711200\n",
      "Epoch176, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.711500\n",
      "Epoch177, loss-363.568526, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000000\n",
      "Test Accuracy: 0.711500\n",
      "Epoch178, loss-363.568499, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000027\n",
      "Test Accuracy: 0.710100\n",
      "Epoch179, loss-363.568406, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000121\n",
      "Test Accuracy: 0.714500\n",
      "Epoch180, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:-0.000001\n",
      "Test Accuracy: 0.714500\n",
      "Epoch181, loss-363.568478, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000048\n",
      "Test Accuracy: 0.716600\n",
      "Epoch182, loss-363.567560, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000967\n",
      "Test Accuracy: 0.701500\n",
      "Epoch183, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.701200\n",
      "Epoch184, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.701200\n",
      "Epoch185, loss-363.568333, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000193\n",
      "Test Accuracy: 0.712000\n",
      "Epoch186, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.712000\n",
      "Epoch187, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000000\n",
      "Test Accuracy: 0.712000\n",
      "Epoch188, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.712100\n",
      "Epoch189, loss-363.568397, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000129\n",
      "Test Accuracy: 0.716200\n",
      "Epoch190, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.716200\n",
      "Epoch191, loss-363.568524, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.716300\n",
      "Epoch192, loss-363.568397, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000130\n",
      "Test Accuracy: 0.716500\n",
      "Epoch193, loss-363.568479, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000047\n",
      "Test Accuracy: 0.708100\n",
      "Epoch194, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.707600\n",
      "Epoch195, loss-363.568393, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000132\n",
      "Test Accuracy: 0.706200\n",
      "Epoch196, loss-363.568525, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000001\n",
      "Test Accuracy: 0.706200\n",
      "Epoch197, loss-363.568523, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000002\n",
      "Test Accuracy: 0.705800\n",
      "Epoch198, loss-363.568444, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000082\n",
      "Test Accuracy: 0.699600\n",
      "Epoch199, loss-363.568459, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000067\n",
      "Test Accuracy: 0.698800\n",
      "Epoch200, loss-363.568514, loss_oh:233.901100, loss_ie:-119.393728, loss_a:-5.009840, loss_kd:0.000013\n",
      "Test Accuracy: 0.698200\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "保存训练数据"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "\n",
    "save_list(loss_l, test_path, 'loss.txt')\n",
    "save_list(loss_ie_l, test_path, 'loss_ie.txt')\n",
    "save_list(loss_a_l, test_path, 'loss_a.txt')\n",
    "save_list(loss_kd_l, test_path, 'loss_kd.txt')\n",
    "save_list(loss_oh_l, test_path, 'loss_oh.txt')\n",
    "save_list(accr_l, test_path, 'accr.txt')\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/yinzp/workspace/testdata/loss.txt'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-dea20c144c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_ie_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss_ie.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_a_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss_a.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_kd_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss_kd.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_oh_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss_oh.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-a92d427e5071>\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(list, path, filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/yinzp/workspace/testdata/loss.txt'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}